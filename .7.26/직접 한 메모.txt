데이터 분석의 본질은 시각화를 해서 한눈에 알아보기 위해서
xAPI와 IMS Caliper Analytics는 학습 활동 정보 수집을 위한 대표적인 표준
천재교육의 핵심 논리들을 실현시키기 위해서는 stt,llm 등의 기반시스템이 필요한데, 그것들을 이용하려면 데이터 분석이 중요하다.
데이터 분석은 업종에 대한 이해도가 중요함. 데이터는 업종의 특성에 따라 다르게 저장되어 사용된다.
머신러닝을 통해서 데이터에서 룰을 뽑아 내는 것  : 예를 들어 탈퇴하는 사람들이 어떤 특성을 가졌고 최종 접속일이 얼마나 됐는지 등등을 분석해서 공식을 뽑아냄 = 데이터 트레이닝 
데이터 양이 많아진다면 시스템 사양을 뽑아내는 데 더 오래걸린다. 그 기술 스펙을 구현해내는 것이 mlops 엔지니어.
천재교육에서 제일 중요한 분석 대상은 문제를 맞출 확률을 맞추는 것인데 그 일들은 mlops 엔지니어들이 머신러닝을 통해서 한다.
여러가지 루트에서 데이터를 수집하고, 데이터를 ods에 저장하고, raw로 바꾸는 역할을 데이터 엔지니어가 한다. 그것을 머신러닝시키는 사람들은 mlops 엔지니어들이 한다.

맞춤형 교육이 중요
맞춤형 교육을 하기 위해서는 수준을 진단해야 함. 시험을 많이 보는 등
그리고 그 진단의 결과를 해석한다.(약점, 유형의 익숙함, 개념에 대한 이해 여부 등) 
그리고 그 분석의 결과에 적절한 추천(처방)을 받도록 해야 한다.(개념 보강 영상, 동일 유형 반복 풀이, 적절한 난이도 부여, 오답 유사 문제 부여 등)

수준을 예측할땐 미래 예측, 약점을 예측할땐 과거 진단 : 이것이 진단 프로세스의 핵심
지식맵 기반 선후행 계통도를 따라서 과거에 배운 개념 중 무슨 개념이 부족했는지 진단

 knowledge tracing : 지식을 추적한다 : 시간의 흐름에 따라 즉 공부량이늘어감에 따라 사람의 특정 지식의 숙련도는 올라간다. -> 문제를 맞출 확률이 높아진다.
그중에 dkt 라는 것이 있는데, 시간의 흐름에 따라 변화하는 학습자의 과거 학습이력 데이터를 학습하려 지식의 숙련 상태를 예측하는 모델로서 현재 상용화가 가장 많은 모델

딥러닝 계열엔 DNN, RNN, CNN 세 계열이 있음
cnn: 그림처럼 구조화된 좌표 중심(물체 인식), rnn : 시간에 흐름 중심, dnn : 정보 스택 중심
rnn을 이용하면 좋지만 앞전의 문제들 개수가 적으면 예측 성공 가능성이 떨어짐
그를 위해 FM모델을 사용한다. 유저와 문제의 정오답같은 단순 정보 뿐만 아니라, 학습자의 성적이나 문제의 고유 정보등 부가적인 feature를 바영하여 사용자의 풀어보지 못한 문제를 맞출 확률을 예측한다.
irt 모델 : 평가 문항들에 대한 응답에 근거하여 피험자의 잠재적인 특성이나 평가 문항의 난이도/ 변별도를 측정하기 위한 검사 이론.
개인의 능력, 문제의 난이도, 변별도를 구할 때, 평가 문제에 대한 정답 여부와 같은 이항 결과에 기반하여 확률적으로 접근함.


cat 방법 : 컴퓨터화 적응형 시험은 응시자의 능력 수준을 측정하기 위한 시험 형태. 각 응시자에게 맞춤형 문항을 제공하여 효율적으로 능력을 평가
cat는 응시자의 답변에 따라 다음 문항이 동적으로 선택되어 제시됨 (시간 절약) 적은 문제수로 빠르게 수준을 진단할 수 있음

ocr : cnn(동물들이 물체를 인식하거나 구분하는 것을 모티브로 한 신경망으로 대상의 특정 부분을 민감하게 받아들여 대상을 구분하는 것을 아이디어로 하여 등장) 을 이용하여 필기체를 인식하거나 비슷한 그림을 찾아주는 기능을 함.

유사도 기반 챗봇 : 단어의 의미를 n차원 공간에서 벡터화 시키는 방법으로 '비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다'는 가정.

인간의 언어를(자연어) 수치화 하는 것이 임베딩이다. 자연어를 수치화해서 벡터공간에 표현한다.

stt : 음성을 받아서 텍스트로 전환.

대형 언어 모델 : rnn을 쓰다가, transformers 로 인해서 발전.  foundation model을 이용하여 여러가지 언어로 서비스를 제공할 수 있게 됨.

rag 방법론 : gpt에서 발생하는 거짓말(hallucination)을 줄이기 위해 사용, 문장을 벡터로 표현하여 의미적 유사성을 계산하고 이를 기반으로 정보를 처리함.

데이터 파이프라인 :  데이터를 많은 곳에서 가져와서, etl(데이터 수집 후 추출) 한 후에 data warehouse를 만든 후에 그를 쓰기 편하게 가공해서 데이터 마트를 만들어 여러 곳에 사용함. 이 데이터 파이프라인은 데이터 엔지니어들이 만든다.

우리가 다뤄야 할 데이터는 보통 텍스트 데이터라 양이 많음, 이를 빨리 하기 위해서는 분산 처리를 해야 함. 이 분산 처리를 하둡(hadoop)이라고 한다(비용 아주절감) 데이터 처리를 위한 것 : 하둡, 스파크, 맵리듀스

데이터 수집방식 : 벌크형 : 이미 존재하는 데이터를 정리해 추출 : 연속적이지 않음, 주기적으로 가져오는 것 ex)월별 작업
			 스트리밍형 : 차례대로 생성되는 데이터를 끊임없이 연속적으로 보냄. ex) 행동별 데이터
			배치 처리, 스트림 처리 : 각각 벌크형, 스트리밍형에 사용.
배치 파이프라인 : 일정 시간 간격동안 저장소에 데이터 묶음을 로드한다. 보통 사용량이 적은 업무 시간(새벽 등)
			 보통 월별 회계 같은 연속적으로 분석할 필요가 없는 데이터 세트에 최적
모아놨다가 처리 : 배치, 연속적으로 처리 : 스트림

실시간 처리를 안정적으로 하기 위한 시스템 ; kafka, redis. 등

mwaa : 데이터 가공 활용 공정 과정

medalian : 데이터를 필요한 데이터로 가공하는 표준 프로세스

데이터 처리 가공 mapreduce, sql

athena로 sql query를 작성해서 데이터베이스에서 결과를 가져옴

airflow : 공정들을 관리, 공정 정상 작동 여부 확인

학습 분석학 :
예측 : 학업 성취 예측, 행동 탐지
군집화 ; 유사 학생군 그룹화, 유사한 강의 자료 그룹화
이상치 발견 ;중도 탈락 위기 학생, 특이행동 탐지
사회 연결망 분석 : 의사소통 도구를 통한 협동, 연결 정도로 교육관계, 조직 내 관계 분석
텍스트 마이닝 : 텍스트 기반 내용으로부터 정보 도출 

domain 지식  : 특정 분야 또는 주제에 대한 전문 지식을 의미.
데이터 분석가의 중요한 역량은 도메인(업종)에 대한 이해. 
그를 위해서는 데이터베이스를 이해해야 함, 
그리고 컨설팅 능력이 중요하다.(해설 능력, 문제를 식별하는 능력), 
스토리텔링 능력이 중요하다. 

분석 결과를 수치로 아는 것이 중요하다. 그렇지 않으면 해당 분야 전문가들이 이미 다 아는 내용이라 받아들여지기 어려울 수 있다.
수치로 알려주면 수치로 아는 것 만으로 의미가 생기기 때문에 더 유리하다.

3-tier 분야
front, backend, DB
front에서 정보 입력 -> back에서 정보 식별해서 DB에 저장

그냥 정보를 저장만 해놓으면 텍스트 파일, 그것을 카테고리에 따라 분류해 놓으면 그것이 데이터베이스가 된다.

캘리퍼는 교육 분야에서 만든 것, xAPI는 미국 정부에서 만든것


데이터 마트 : 액세스 하기 쉽고, 인사이트를 신속하게 얻을 수 있도록 미리 만들어 놓는 단순한 형태의 데이터 웨어하우스

데이터 웨어하우스 : 기업 전체에 대한 비즈니스 인텔리전스 및 분석을 지원하도록 설계된 데이터 관리 시스템, 어플 로그 파일 등 광범위한 소스로부터 추출된 것

데이터 레이크  : 정의된 구조 없이 방대한 양의 원시 데이터가 그대로 저장됨, 정형 또는 비정형 데이터를 저장하고, 이를 실시간 분석, 데이터 사이언스 및 머신러닝 사용 사례에 즉시 이용 가능하게 함. 데이터 레이크 사용시 원본 형식 그대로 수집가능

시각화 : 데이터 분석한 것은 시각적으로 명확하게 표현하고 의사소통하는것
한눈에 이해할 수 있도록 표나 차트로 정리
 차이/비교 : 막대그래프 등
방향성 : 라인 그래프 등
군집 : 산점도 등
분포 : 분포그래프 등

프로세스 마이닝 : 이벤트로그 데이터 분석을 통해 어떤 일이 어떻게 흘러가는지, 어떤 상품이 어떤 과정으로 제작되는지, 한 고객이 서비스 내에서 어떤 여정을 거치는지 등의 프로세스를 도출해내는 것
시스템에 있는 로그들을 분석하면, 제품들의 제작 과정과 서비스를 이용하는 과정 등을 예측하는 것이 가능해진다.

로그들을 분석하고 취약점을 개선하고..
처리가 오래 걸리는 곳, 이용자가 많이 빠져나가는 곳 등을 분석해서 알아내어 개선한다. 


































