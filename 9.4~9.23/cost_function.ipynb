{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "y = np.array([3, 5, 7, 9], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(0.0) # 가중치\n",
    "b = tf.Variable(0.0) # 편향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(X):\n",
    "    return W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))  # reduce_mean : 평균, square : 제곱(값을 여러개 리스트로 넣으면 하나하나 제곱해줌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 과정 정의\n",
    "def train_step(X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = linear_model(X)\n",
    "        loss = mean_squared_error(y, y_pred)\n",
    "    gradients = tape.gradient(loss, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 41.0\n",
      "Epoch 100: Loss: 0.007531234994530678\n",
      "Epoch 200: Loss: 0.0041345576755702496\n",
      "Epoch 300: Loss: 0.002269820310175419\n",
      "Epoch 400: Loss: 0.0012461235746741295\n",
      "Epoch 500: Loss: 0.0006841050344519317\n",
      "Epoch 600: Loss: 0.0003755530924536288\n",
      "Epoch 700: Loss: 0.0002061743725789711\n",
      "Epoch 800: Loss: 0.00011318828910589218\n",
      "Epoch 900: Loss: 6.213805318111554e-05\n"
     ]
    }
   ],
   "source": [
    "# 100번 단위로 학습 반복하며 오차 비교해보기\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(X, y)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 W: 2.0048611164093018\n",
      "학습된 b: 0.9857079386711121\n"
     ]
    }
   ],
   "source": [
    "# 학습된 W, b 출력\n",
    "print(f\"학습된 W: {W.numpy()}\")\n",
    "print(f\"학습된 b: {b.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과: [11.010014 13.014875]\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과\n",
    "X_test = np.array([5, 6], dtype=np.float32)\n",
    "y_test_pred = linear_model(X_test)\n",
    "print(f\"예측 결과: {y_test_pred.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다른 평가지표 구현하기\n",
    "## 평가지표에 따른 손실값 확인 및 시각화(선택) 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나는 R스퀘어 해보기로 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    residual_sum_of_squares = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    total_sum_of_squares = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    r2 = 1 - residual_sum_of_squares / (total_sum_of_squares + tf.keras.backend.epsilon())\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = linear_model(X)\n",
    "        loss = r_squared(y, y_pred)\n",
    "    gradients = tape.gradient(loss, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.9999932050704956\n",
      "Epoch 100: Loss: 0.999992311000824\n",
      "Epoch 200: Loss: 0.9999908208847046\n",
      "Epoch 300: Loss: 0.9996452331542969\n",
      "Epoch 400: Loss: 0.7535979747772217\n",
      "Epoch 500: Loss: -174.9620819091797\n",
      "Epoch 600: Loss: -125663.546875\n",
      "Epoch 700: Loss: -89744304.0\n",
      "Epoch 800: Loss: -64091545600.0\n",
      "Epoch 900: Loss: -45771432919040.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "epochlist = []\n",
    "losslist = []\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(X, y)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {loss.numpy()}\")\n",
    "        epochlist.append(epoch)\n",
    "        losslist.append(loss.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 W: -132451696.0\n",
      "학습된 b: -45049728.0\n"
     ]
    }
   ],
   "source": [
    "# 학습된 W, b 출력\n",
    "print(f\"학습된 W: {W.numpy()}\")\n",
    "print(f\"학습된 b: {b.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과: [-7.073082e+08 -8.397599e+08]\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과\n",
    "X_test = np.array([5, 6], dtype=np.float32)\n",
    "y_test_pred = linear_model(X_test)\n",
    "print(f\"예측 결과: {y_test_pred.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "lossdf = pd.DataFrame(losslist, columns=['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochdf = pd.DataFrame(epochlist, columns=['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.999932e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>9.999923e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>9.999908e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>9.996452e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>7.535980e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>-1.749621e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600</td>\n",
       "      <td>-1.256635e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>700</td>\n",
       "      <td>-8.974430e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>800</td>\n",
       "      <td>-6.409155e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>900</td>\n",
       "      <td>-4.577143e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch          loss\n",
       "0      0  9.999932e-01\n",
       "1    100  9.999923e-01\n",
       "2    200  9.999908e-01\n",
       "3    300  9.996452e-01\n",
       "4    400  7.535980e-01\n",
       "5    500 -1.749621e+02\n",
       "6    600 -1.256635e+05\n",
       "7    700 -8.974430e+07\n",
       "8    800 -6.409155e+10\n",
       "9    900 -4.577143e+13"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([epochdf,lossdf], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해설 : RMSE 써보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 6.4031243324279785\n",
      "Epoch 100: Loss: 0.07388278096914291\n",
      "Epoch 200: Loss: 0.04142230749130249\n",
      "Epoch 300: Loss: 0.04143679887056351\n",
      "Epoch 400: Loss: 0.04144427180290222\n",
      "Epoch 500: Loss: 0.04144619032740593\n",
      "Epoch 600: Loss: 0.04144619032740593\n",
      "Epoch 700: Loss: 0.04144619032740593\n",
      "Epoch 800: Loss: 0.04144619032740593\n",
      "Epoch 900: Loss: 0.04144619032740593\n",
      "학습된 W: 2.0135791301727295\n",
      "학습된 b: 1.0046178102493286\n",
      "예측 결과: [11.072514 13.086092]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 생성 (y = 2x + 1)\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "y = np.array([3, 5, 7, 9], dtype=np.float32)\n",
    "\n",
    "# 가중치, 바이어스 초기화\n",
    "W = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "def linear_model(X):\n",
    "    return W * X + b\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# 학습 과정 정의\n",
    "def train_step(X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = linear_model(X)\n",
    "        loss = rmse(y, y_pred)\n",
    "    gradients = tape.gradient(loss, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    return loss\n",
    "\n",
    "# 학습 반복\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(X, y)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {loss.numpy()}\")\n",
    "\n",
    "# 학습된 파라미터 출력\n",
    "print(f\"학습된 W: {W.numpy()}\")\n",
    "print(f\"학습된 b: {b.numpy()}\")\n",
    "\n",
    "# 예측 결과 출력\n",
    "X_test = np.array([5, 6], dtype=np.float32)\n",
    "y_test_pred = linear_model(X_test)\n",
    "print(f\"예측 결과: {y_test_pred.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해설 : 교차 엔트로피 검증 해보기 위해 분류모델 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0,1,0], [1,0,0], [0,1,0]])\n",
    "y_pred = np.array([[0.1,0.7,0.2], [0.8,0.1,0.15],[0.2,0.6,0.3]]) # 답은 맞추겠지만, 확률 오차값이 누적될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.41158148766423003>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred)) # 첫번쨰, 두번째, 세번째를 예측한 확률들과 생기는 오차를 평균낸것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.21666666666666667>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.abs(y_true -  y_pred)) # MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.05583333333333334>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.square(y_true -  y_pred)) # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.23629078131263043>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(tf.reduce_mean(tf.square(y_true -  y_pred))) # RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
