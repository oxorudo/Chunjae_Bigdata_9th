{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML 문서 요청\n",
    "\n",
    "import requests\n",
    "\n",
    "# beautiful soup 모듈 불러오기\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# 요청 주소\n",
    "url = \"https://example.com\"\n",
    "\n",
    "# 요청 - get(url) 메서드\n",
    "response = requests.get(url)\n",
    "\n",
    "# 상태 코드 속성 추출\n",
    "status_code = response.status_code\n",
    "\n",
    "if status_code == 200:\n",
    "    # html 문서 속성, .text\n",
    "    # print((response.text))\n",
    "    # beautifulsoup 객체 생성\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    print(type(soup))  # str가 아님\n",
    "\n",
    "    # BeautifulSoup.find(태그이름) : 단일 탐색 메서드 -> 가장 처음 나온 요소만 반환\n",
    "    p_tag = soup.find(\"p\")\n",
    "    print(p_tag.text)\n",
    "\n",
    "    # soup 인스턴스 내부에서 h1 태그를 찾아서 텍스트를 출력\n",
    "\n",
    "    h1_tag = soup.find(\"h1\")\n",
    "    print(h1_tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복수(여러 개) 탐색\n",
    "\n",
    "import requests\n",
    "\n",
    "# beautiful soup 모듈 불러오기\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# 요청 주소\n",
    "url = \"https://example.com\"\n",
    "\n",
    "# 요청 - get(url) 메서드\n",
    "response = requests.get(url)\n",
    "\n",
    "# 상태 코드 속성 추출\n",
    "status_code = response.status_code\n",
    "\n",
    "if status_code == 200:\n",
    "    # html 문서 속성, .text\n",
    "    # print((response.text))\n",
    "    # beautifulsoup 객체 생성\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Beautiflsoup.find_all() : 복수 요소(태그) 탐색\n",
    "    p_tag_list = soup.find_all(\"p\")\n",
    "\n",
    "    print(p_tag_list)  # .text는 안됨(리스트 형태이기 때문)\n",
    "    print(type(p_tag_list))  # 리스트를 반환\n",
    "\n",
    "    # 반복문을 활용해서 개별 요소 텍스트 출력\n",
    "    for i in p_tag_list:\n",
    "        print(i.text)\n",
    "\n",
    "    # 태그가 1개라도 반환값은 리스트\n",
    "    h1_tag_list = soup.find_all(\"h1\")\n",
    "    print(h1_tag_list[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a 태그를 찾아서 텍스트를 출력\n",
    "a_tag_list = soup.find(\"a\")\n",
    "print(a_tag_list.text)\n",
    "\n",
    "# a 태그의 속성(href) 추출\n",
    "a_tag_href = a_tag_list[\"href\"]  # 딕셔너리와 비슷\n",
    "print(a_tag_href)\n",
    "\n",
    "# 태그의 속성 목록 추출\n",
    "a_tag_attr_list = a_tag_list.attrs\n",
    "print(a_tag_attr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# beautiful soup 모듈 불러오기\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# 요청 주소\n",
    "url = \"https://quotes.toscrape.com/\"\n",
    "\n",
    "# 요청 - get(url) 메서드\n",
    "response = requests.get(url)\n",
    "\n",
    "# 상태 코드 속성 추출\n",
    "status_code = response.status_code\n",
    "\n",
    "if status_code == 200:\n",
    "    # html 문서 속성, .text\n",
    "    # print((response.text))\n",
    "    # beautifulsoup 객체 생성\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # span 태그, class == text (span은 p와 비슷한 역할)\n",
    "    quote_text = soup.find(\n",
    "        \"span\", attrs={\"class\": \"text\"}\n",
    "    )  # 태그가 span이고 속성 목록이 클래스: 텍스트인 것을 탐색\n",
    "    print(quote_text.text)\n",
    "\n",
    "    # 복수 요소 탐색\n",
    "    # span 태그, class가 text인 모든 요소의 텍스트 출력\n",
    "    quote_texts = soup.find_all(\"span\", attrs={\"class\": \"text\"})\n",
    "    for text in quote_texts:  # 텍스트 리스트의 원소를 순회하며 출력\n",
    "        print(text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# beautiful soup 모듈 불러오기\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# 요청 주소\n",
    "url = \"https://quotes.toscrape.com/\"\n",
    "\n",
    "# 요청 - get(url) 메서드\n",
    "response = requests.get(url)\n",
    "\n",
    "# 상태 코드 속성 추출\n",
    "status_code = response.status_code\n",
    "\n",
    "if status_code == 200:\n",
    "    # html 문서 속성, .text\n",
    "    # print((response.text))\n",
    "    # beautifulsoup 객체 생성\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    quote_author_list = []\n",
    "\n",
    "    # div 태그, class가 quote인 요소 복수 탐색\n",
    "    quote_list = soup.find_all(\"div\", attrs={\"class\": \"quote\"})\n",
    "    for quote in quote_list:\n",
    "        # quote 요소 내부에서 태그는 span, 클래스는 text 요소 탐색\n",
    "        quote_text = quote.find(\"span\", attrs={\"class\": \"text\"})\n",
    "        # print(quote_text.text)\n",
    "\n",
    "        # 인물 정보도 탐색\n",
    "        quote_author_text = quote.find(\"small\", attrs={\"class\": \"author\"})\n",
    "        # print(quote_author_text.text)\n",
    "\n",
    "        # {\"quote\": 인용문 데이터, \"author\": 인물 데이터} 딕셔너리\n",
    "        quote_author_dic = {\n",
    "            \"quote\": quote_text.text,\n",
    "            \"author\": quote_author_text.text,\n",
    "        }\n",
    "        # quote_author_list에 저장(추가 append)\n",
    "        quote_author_list.append(quote_author_dic)\n",
    "\n",
    "pprint(quote_author_list)  # pprint = 예쁘게 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "quote_author_list = []\n",
    "\n",
    "# \"https://quotes.toscrape.com/page/숫자/\" <-같이 숫자가 바뀌면 페이지가 바뀜\n",
    "# 1 -> 10\n",
    "# f-string 활용 -> f\"https://quotes.toscrape.com/page/{숫자}/\"\n",
    "for page in range(1, 6):\n",
    "    url = f\"https://quotes.toscrape.com/page/{page}/\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    status_code = response.status_code\n",
    "\n",
    "    if status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        quote_list = soup.find_all(\"div\", attrs={\"class\": \"quote\"})\n",
    "\n",
    "        for quote in quote_list:\n",
    "\n",
    "            quote_text = quote.find(\"span\", attrs={\"class\": \"text\"})\n",
    "\n",
    "            quote_author = quote.find(\"small\", attrs={\"class\": \"author\"})\n",
    "\n",
    "            quote_author_dict = {\"quote\": quote_text.text, \"author\": quote_author.text}\n",
    "\n",
    "            quote_author_list.append(quote_author_dict)\n",
    "\n",
    "pprint(quote_author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
